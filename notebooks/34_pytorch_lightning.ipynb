{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562b56de-d1f0-46cd-a5d6-9decf518eb51",
   "metadata": {},
   "source": [
    "# PyTorch Lightning\n",
    "\n",
    "We want to use PyTorch Lightning  now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1edf75-99e3-40ed-984b-2d182849d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets.utils import download_and_extract_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c597b25-679c-44cc-8cc6-6de99ecfb0b9",
   "metadata": {},
   "source": [
    "## Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c05b983-5595-41d8-9562-e206bbea28ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dl_path='./tmp', batch_size = 32, num_workers=0, cache_dataset=True):\n",
    "        super().__init__()\n",
    "        self._dl_path = dl_path\n",
    "        self._batch_size = batch_size\n",
    "        self._num_workers = num_workers\n",
    "        self._cache_dataset = cache_dataset\n",
    "\n",
    "    @property\n",
    "    def data_path(self):\n",
    "        return Path(self._dl_path).joinpath(\"PetImages\")\n",
    "\n",
    "    @property\n",
    "    def normalize_transform(self):\n",
    "        return transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    @property\n",
    "    def train_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize_transform,\n",
    "        ])\n",
    "\n",
    "    @property\n",
    "    def val_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)), \n",
    "            transforms.ToTensor(), \n",
    "            self.normalize_transform\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download images and prepare images datasets.\"\"\"\n",
    "        url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'  \n",
    "        if len(os.listdir(self.data_path)) == 0:\n",
    "            download_and_extract_archive(url=url, download_root=self._dl_path, remove_finished=not self._cache_dataset)\n",
    "        else:\n",
    "            print(\"Dataset already exists, skipping download and extraction...\")\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # make assignments here (val/train/test split)\n",
    "        dataset = self.create_dataset(self.data_path, self.train_transform)\n",
    "        self.train_data, self.val_data = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "        print(\"Dataset created, split:\")\n",
    "        print(f'training images: {len(self.train_data)}')\n",
    "        print(f'validation images: {len(self.val_data)}')\n",
    "        #self.log.info(\"Dataset created, split:\")\n",
    "        #log.info(f'training images: {len(self.train_data)}')\n",
    "        #log.info(f'validation images: {len(self.val_data)}')\n",
    "\n",
    "    def create_dataset(self, root, transform):\n",
    "        return ImageFolder(root=root, transform=transform, is_valid_file=self._is_image_valid)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        #self.log.info(\"Training data loaded.\")\n",
    "        return DataLoader(dataset=self.train_data, batch_size=self._batch_size, num_workers=self._num_workers, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        #log.info(\"Validation data loaded.\")\n",
    "        return DataLoader(dataset=self.val_data, batch_size=self._batch_size, num_workers=self._num_workers, shuffle=False)\n",
    "\n",
    "    def _is_image_valid(self, image_path):\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9caa1a91-9047-468f-8a36-4a5fc242290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = CatDogImageDataModule(num_workers=16) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e61e4a8-b2b3-48c6-96bb-d9176d6b90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c24e2fc-7b8a-4c88-89cc-e1e9037f6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8e92f-c7cb-4821-bd2d-6da2b2e23da8",
   "metadata": {},
   "source": [
    "## Build Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8eda0e1-a4fc-4b4c-ba8e-14b735f6bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Sequential(nn.Conv2d(3, 16, 3), nn.ReLU(), nn.MaxPool2d(2,2))\n",
    "        self.conv_2 = nn.Sequential(nn.Conv2d(16, 32, 3), nn.ReLU(), nn.MaxPool2d(2,2))\n",
    "        self.conv_3 = nn.Sequential(nn.Conv2d(32, 64, 3), nn.ReLU(), nn.MaxPool2d(2,2))\n",
    "        self.fc_1 = nn.Sequential(nn.Flatten(), nn.Linear(43264,256), nn.ReLU(), nn.Linear(256,128), nn.ReLU())\n",
    "        self.fc_2 = nn.Sequential(nn.Linear(128,2),)\n",
    "\n",
    "        #mat1 and mat2 shapes cannot be multiplied (32x43264 and 1600x256)\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "      return F.nll_loss(logits, labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, label = batch\n",
    "        output = self.forward(data)\n",
    "        loss = nn.CrossEntropyLoss()(output,label)\n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss, 'log': self.log}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        val_data, val_label = batch\n",
    "        val_output = self.forward(val_data)\n",
    "        val_loss = nn.CrossEntropyLoss()(val_output, val_label)\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        return F.softmax(x,dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0410169-183d-4e71-b23f-18c067154005",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d22a770-d8b7-46de-93fa-38a8c3926a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69337d-dadb-4bd0-8528-da158ede7129",
   "metadata": {},
   "source": [
    "## Setup trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dde40-910a-4669-95a9-95a09c58b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists, skipping download and extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created, split:\n",
      "training images: 19999\n",
      "validation images: 4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | conv_1 | Sequential | 448   \n",
      "1 | conv_2 | Sequential | 4.6 K \n",
      "2 | conv_3 | Sequential | 18.5 K\n",
      "3 | fc_1   | Sequential | 11.1 M\n",
      "4 | fc_2   | Sequential | 258   \n",
      "--------------------------------------\n",
      "11.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.1 M    Total params\n",
      "44.530    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb439093102e470aaa92536bdc131e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20)\n",
    "\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a16b0-3ef7-4275-b171-1bb9335e9e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
